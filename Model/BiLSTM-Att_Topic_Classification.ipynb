{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "950a043d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import warnings\n",
    "import pickle\n",
    "import datetime\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import traceback\n",
    "import time \n",
    "import json\n",
    "import numpy as np \n",
    "from collections import defaultdict\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input \n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Embedding, BatchNormalization\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "path='/Users/wangshihang/Documents/Code/CharCnn_Keras-master/data/ag_news_csv/train.csv'\n",
    "word_dict = defaultdict(int)\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    rdr = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for row in rdr:\n",
    "        txt = re.sub(\"^\\s*(.-)\\s*$\", \"%1\", row[2]).replace(\"\\\\n\", \"\\n\").replace('\\\\', ' ')\n",
    "        txt = txt.split()\n",
    "        for word in txt:\n",
    "            word_dict[word.lower()]+=1\n",
    "word_list=sorted(word_dict.items(), key=lambda d: -d[1])\n",
    "word_index={'<pad>': 0, '<start>': 1, '<unknown>': 2, '<unused>': 3}\n",
    "for i in range(29996):\n",
    "    word_index[word_list[i][0]]=i+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84178499",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(raw_y, num_classes):\n",
    "    index = np.array(raw_y)\n",
    "    out = np.zeros((index.shape[0], num_classes))\n",
    "    out[np.arange(index.shape[0]), index-1] = 1\n",
    "    return out \n",
    "\n",
    "def load_data(path, max_seq_len, word_index, num_classes):\n",
    "    raw_y = []\n",
    "    raw_x = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        rdr = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        for row in rdr:\n",
    "            raw_y.append(int(row[0]))\n",
    "            txt = re.sub(\"^\\s*(.-)\\s*$\", \"%1\", row[2]).replace(\"\\\\n\", \"\\n\").replace('\\\\', ' ').split()\n",
    "            txt_len = len(txt)\n",
    "            x = np.zeros(max_seq_len, dtype = np.int32)\n",
    "            if txt_len <= max_seq_len:\n",
    "                for i in range(txt_len):\n",
    "                    try:\n",
    "                        x[i]=word_index[txt[i]]\n",
    "                    except:\n",
    "                        x[i]=2\n",
    "            else:\n",
    "                for i in range(txt_len-max_seq_len, txt_len):\n",
    "                    try:\n",
    "                        x[i - txt_len + max_seq_len] = word_index[txt[i]]\n",
    "                    except:\n",
    "                        x[i - txt_len + max_seq_len]=2\n",
    "            raw_x.append(x)\n",
    "    all_x = np.array(raw_x)\n",
    "    all_y = one_hot_encode(raw_y, num_classes)\n",
    "    return all_x, all_y\n",
    "\n",
    "def batch_iter(x, y, batch_size = 32):\n",
    "    data_len = len(x)\n",
    "    num_batch = (data_len + batch_size - 1) // batch_size\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuff = x[indices]\n",
    "    y_shuff = y[indices]\n",
    "    for i in range(num_batch):\n",
    "        start_offset = i*batch_size \n",
    "        end_offset = min(start_offset + batch_size, data_len)\n",
    "        yield i, num_batch, x_shuff[start_offset:end_offset], y_shuff[start_offset:end_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "7205e60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnAttentionLayer(layers.Layer):\n",
    "    def __init__(self, attention_size, drop_rate):\n",
    "        super().__init__()\n",
    "        self.attention_size = attention_size\n",
    "        self.dropout = Dropout(drop_rate, name = \"rnn_attention_dropout\")\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.attention_w = self.add_weight(name = \"atten_w\", shape = (input_shape[-1], self.attention_size),\n",
    "                                           initializer = tf.random_uniform_initializer(), dtype = \"float32\",\n",
    "                                           trainable = True)\n",
    "        self.attention_u = self.add_weight(name = \"atten_u\", shape = (self.attention_size,),\n",
    "                                           initializer = tf.random_uniform_initializer(), dtype = \"float32\",\n",
    "                                           trainable = True)\n",
    "        self.attention_b = self.add_weight(name = \"atten_b\", shape = (self.attention_size,),\n",
    "                                           initializer = tf.constant_initializer(0.1), dtype = \"float32\",\n",
    "                                           trainable = True)    \n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = tf.tanh(tf.add(tf.tensordot(inputs, self.attention_w, axes = 1), self.attention_b))\n",
    "        x = tf.tensordot(x, self.attention_u, axes = 1)\n",
    "        x = tf.nn.softmax(x)\n",
    "        weight_out = tf.multiply(tf.expand_dims(x, -1), inputs)\n",
    "        final_out = tf.reduce_sum(weight_out, axis = 1) \n",
    "        drop_out = self.dropout(final_out, training = training)\n",
    "        return drop_out\n",
    "\n",
    "class RnnLayer(layers.Layer):\n",
    "    def __init__(self, rnn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        fwd_lstm = LSTM(rnn_size, return_sequences = True, go_backwards= False, dropout = drop_rate,\n",
    "                        name = \"fwd_lstm\")\n",
    "        bwd_lstm = LSTM(rnn_size, return_sequences = True, go_backwards = True, dropout = drop_rate,\n",
    "                        name = \"bwd_lstm\")\n",
    "        self.bilstm = Bidirectional(merge_mode = \"concat\", layer = fwd_lstm, backward_layer = bwd_lstm,\n",
    "                                    name = \"bilstm\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        outputs = self.bilstm(inputs, training = training)\n",
    "        return outputs\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, num_classes, drop_rate, vocab_size, embedding_size, rnn_size, attention_size):\n",
    "        super().__init__()\n",
    "        embedding_weight = self.get_embedding_weight(GLoVe_path, word_index)\n",
    "        self.embedding_layer = Embedding(vocab_size, embedding_size, weights=[embedding_weight],\n",
    "                                         name = \"embeding_0\")\n",
    "        self.rnn_layer = RnnLayer(rnn_size, drop_rate)\n",
    "        self.attention_layer = RnnAttentionLayer(attention_size, drop_rate)\n",
    "        self.dense_layer = Dense(num_classes, activation = \"softmax\", \n",
    "                                 kernel_regularizer=keras.regularizers.l2(0.001), name = \"dense_1\")\n",
    "\n",
    "    def call(self, input_x, training):\n",
    "        x = self.embedding_layer(input_x)\n",
    "        x = self.rnn_layer(x, training = training)\n",
    "        x = self.attention_layer(x, training = training)\n",
    "        x = self.dense_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_embedding_weight(self, weight_path, word_index):\n",
    "        embedding_weight = np.random.uniform(-0.05, 0.05, size=[30000, 100])\n",
    "        cnt = 0\n",
    "        with open(weight_path, 'r') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0].lower()\n",
    "                if word in word_index.keys() and word_index[word]< 30000:\n",
    "                    weight = np.asarray(values[1:], dtype='float32')\n",
    "                    embedding_weight[word_index[word]] = weight\n",
    "                    cnt += 1\n",
    "        print('word num: {}, matched num: {}'.format(len(word_index), cnt))\n",
    "        return embedding_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "f73095d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xy_train, xy_val, num_classes, vocab_size, epoches, batch_size):\n",
    "    best_acc = 0\n",
    "    uniq_cfg_name = datetime.datetime.now().strftime(\"%Y\")\n",
    "    checkpoint_prefix = os.path.join(os.getcwd(), \"checkpoints\")\n",
    "    if not os.path.exists(checkpoint_prefix):\n",
    "        print(\"create model dir: %s\" % checkpoint_prefix)\n",
    "        os.mkdir(checkpoint_prefix)\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_prefix, uniq_cfg_name)\n",
    "    model = Model(num_classes, drop_rate = 0.05, vocab_size = vocab_size, embedding_size = 100,\n",
    "                  rnn_size = 128, attention_size = 128)\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print(\"load weight from: %s\" % checkpoint_path)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
    "    accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "    @tf.function \n",
    "    def train_step(input_x, input_y, training = True):\n",
    "        if training:\n",
    "            with tf.GradientTape() as tape:\n",
    "                raw_prob = model(input_x, training)\n",
    "                pred_loss = loss_fn(input_y, raw_prob)\n",
    "            gradients = tape.gradient(pred_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        else:\n",
    "            raw_prob = model(input_x, training)\n",
    "            pred_loss = loss_fn(input_y, raw_prob)\n",
    "        # Update the metrics\n",
    "        loss_metric.update_state(pred_loss)\n",
    "        accuracy_metric.update_state(input_y, raw_prob)\n",
    "        return raw_prob \n",
    "\n",
    "    for i in range(epoches):\n",
    "        t0 = time.time()\n",
    "        batch_train = batch_iter(xy_train[0], xy_train[1], batch_size = batch_size)\n",
    "        loss_metric.reset_states()\n",
    "        accuracy_metric.reset_states()\n",
    "\n",
    "        for batch_no, batch_tot, data_x, data_y in batch_train:\n",
    "            predict_prob = train_step(data_x, data_y, True)  \n",
    "      \n",
    "        print(\"[train ep %d] [%s]: %0.3f  [%s]: %0.3f\" %  (i, \"loss\", loss_metric.result() ,\n",
    "                                                           \"acc\", accuracy_metric.result()))\n",
    "\n",
    "        model.save_weights(checkpoint_path, overwrite=True)\n",
    "        \n",
    "        loss_metric.reset_states()\n",
    "        accuracy_metric.reset_states()\n",
    "        batch_test = batch_iter(xy_val[0], xy_val[1], batch_size = batch_size)\n",
    "        for _, _, data_x, data_y in batch_test:\n",
    "            train_step(data_x, data_y, False)\n",
    "        print(\"[***** ep %d] [%s]: %0.3f  [%s]: %0.3f\" %  (i, \"loss\", loss_metric.result() ,\n",
    "                                                           \"acc\", accuracy_metric.result()))\n",
    "        if accuracy_metric.result()>best_acc:\n",
    "            model.save('./model/topic_cls')\n",
    "            best_acc=accuracy_metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "84b82e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word num: 30000, matched num: 19017\n",
      "[train ep 0] [loss]: 0.353  [acc]: 0.872\n",
      "[***** ep 0] [loss]: 0.316  [acc]: 0.889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/topic_cls/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model/topic_cls/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train ep 1] [loss]: 0.263  [acc]: 0.905\n",
      "[***** ep 1] [loss]: 0.333  [acc]: 0.880\n",
      "[train ep 2] [loss]: 0.238  [acc]: 0.913\n",
      "[***** ep 2] [loss]: 0.346  [acc]: 0.878\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    max_seq_len = 128\n",
    "    num_classes = 3\n",
    "    vocab_size = 30000\n",
    "    train_path='/Users/wangshihang/Documents/Code/CharCnn_Keras-master/data/ag_news_csv/train.csv'\n",
    "    test_path='/Users/wangshihang/Documents/Code/CharCnn_Keras-master/data/ag_news_csv/test.csv'\n",
    "    GLoVe_path = '/Users/wangshihang/Documents/Code/Glove/glove.twitter.27B.100d.txt'\n",
    "\n",
    "    ### gen samples ###\n",
    "    train_x, train_y = load_data(train_path, max_seq_len, word_index, num_classes)\n",
    "    test_x, test_y = load_data(test_path, max_seq_len, word_index, num_classes)\n",
    "    key, freq = np.unique(np.argmax(train_y, axis = 1), return_counts = True)\n",
    "    train([train_x, train_y], [test_x, test_y], num_classes, vocab_size, epoches = 3, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c46a49f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 128\n",
    "num_classes = 3\n",
    "test_path='/Users/wangshihang/Documents/Code/CharCnn_Keras-master/data/ag_news_csv/test.csv'\n",
    "test_x, test_y = load_data(test_path, max_seq_len, word_index, num_classes)\n",
    "\n",
    "model = tf.keras.models.load_model(\"./model/topic_cls\")\n",
    "preds = []\n",
    "for i in range(238):\n",
    "    input_x=test_x[i*32:(i+1)*32]\n",
    "    raw_prob = model(input_x, training=False).numpy()\n",
    "    label = np.argmax(raw_prob,axis=1)\n",
    "    preds.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "58eab290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.000921806442110162"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = []\n",
    "start_time=time.time()\n",
    "for i in range(238):\n",
    "    input_x=test_x[i*32:(i+1)*32]\n",
    "    raw_prob = model(input_x, training=False).numpy()\n",
    "    label = np.argmax(raw_prob,axis=1)\n",
    "    preds.extend(label)\n",
    "end_time=time.time()\n",
    "(end_time-start_time)/len(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b978db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "labels=np.argmax(test_y, axis=1)\n",
    "cm=confusion_matrix(preds, labels)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ad88c20d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.8889473684210526\n",
      "pre:  0.8748061010377491\n",
      "rcl:  0.868859649122807\n",
      "f1:  0.8716745851833126\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('acc: ', metrics.accuracy_score(labels, preds))\n",
    "print('pre: ', metrics.precision_score(labels, preds, average='macro'))\n",
    "print('rcl: ', metrics.recall_score(labels, preds, average='macro'))\n",
    "print('f1: ', metrics.f1_score(labels, preds, average='macro'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
