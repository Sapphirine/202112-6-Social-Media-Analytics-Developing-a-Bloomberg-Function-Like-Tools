{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a5a14b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import csv\n",
    "import warnings\n",
    "import pickle\n",
    "import datetime\n",
    "import tensorflow as tf \n",
    "import pandas as pd\n",
    "import traceback\n",
    "import tqdm\n",
    "import time \n",
    "import json\n",
    "import numpy as np \n",
    "from itertools import islice\n",
    "from collections import defaultdict\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Input \n",
    "from tensorflow.keras.layers import Dense, LSTM, Bidirectional, Dropout, Embedding, BatchNormalization\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "csv.field_size_limit(500 * 1024 * 1024)\n",
    "\n",
    "path='/Users/wangshihang/Documents/Code/fake-news/train.csv'\n",
    "word_dict = defaultdict(int)\n",
    "with open(path, 'r', encoding='utf-8') as f:\n",
    "    rdr = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "    for row in islice(rdr, 1, None):\n",
    "        txt = re.sub(\"^\\s*(.-)\\s*$\", \"%1\", row[3]).replace('\\n', '')\n",
    "        txt = txt.split()\n",
    "        for word in txt:\n",
    "            word_dict[word.lower()]+=1\n",
    "word_list=sorted(word_dict.items(), key=lambda d: -d[1])\n",
    "word_index={'<pad>': 0, '<start>': 1, '<unknown>': 2, '<unused>': 3}\n",
    "for i in range(29996):\n",
    "    word_index[word_list[i][0]]=i+4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "828debf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "from sklearn.utils import shuffle\n",
    "df=pd.read_csv('/Users/wangshihang/Documents/Code/fake-news/train.csv')\n",
    "df = shuffle(df)\n",
    "df1=df[:17800]\n",
    "df2=df[17800:]\n",
    "df1.to_csv('/Users/wangshihang/Documents/Code/fake-news/train2.csv', index=False)\n",
    "df2.to_csv('/Users/wangshihang/Documents/Code/fake-news/valid.csv', index=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0217d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(raw_y, num_classes):\n",
    "    index = np.array(raw_y)\n",
    "    out = np.zeros((index.shape[0], num_classes))\n",
    "    out[np.arange(index.shape[0]), index-1] = 1\n",
    "    return out \n",
    "\n",
    "def load_data(path, max_seq_len, word_index, num_classes):\n",
    "    raw_y = []\n",
    "    raw_x = []\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        rdr = csv.reader(f, delimiter=',', quotechar='\"')\n",
    "        for row in islice(rdr, 1, None):\n",
    "            raw_y.append(int(row[4]))\n",
    "            txt = re.sub(\"^\\s*(.-)\\s*$\", \"%1\", row[3]).replace('\\n', '').split()\n",
    "            txt_len = len(txt)\n",
    "            x = np.zeros(max_seq_len, dtype = np.int32)\n",
    "            if txt_len <= max_seq_len:\n",
    "                for i in range(txt_len):\n",
    "                    try:\n",
    "                        x[i]=word_index[txt[i]]\n",
    "                    except:\n",
    "                        x[i]=2\n",
    "            else:\n",
    "                for i in range(max_seq_len):\n",
    "                    try:\n",
    "                        x[i] = word_index[txt[i]]\n",
    "                    except:\n",
    "                        x[i]=2\n",
    "            raw_x.append(x)\n",
    "    all_x = np.array(raw_x)\n",
    "    all_y = one_hot_encode(raw_y, num_classes)\n",
    "    return all_x, all_y\n",
    "\n",
    "def batch_iter(x, y, batch_size = 32):\n",
    "    data_len = len(x)\n",
    "    num_batch = (data_len + batch_size - 1) // batch_size\n",
    "    indices = np.random.permutation(np.arange(data_len))\n",
    "    x_shuff = x[indices]\n",
    "    y_shuff = y[indices]\n",
    "    for i in range(num_batch):\n",
    "        start_offset = i*batch_size \n",
    "        end_offset = min(start_offset + batch_size, data_len)\n",
    "        yield i, num_batch, x_shuff[start_offset:end_offset], y_shuff[start_offset:end_offset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "58ede94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RnnAttentionLayer(layers.Layer):\n",
    "    def __init__(self, attention_size, drop_rate):\n",
    "        super().__init__()\n",
    "        self.attention_size = attention_size\n",
    "        self.dropout = Dropout(drop_rate, name = \"rnn_attention_dropout\")\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        self.attention_w = self.add_weight(name = \"atten_w\", shape = (input_shape[-1], self.attention_size),\n",
    "                                           initializer = tf.random_uniform_initializer(), dtype = \"float32\",\n",
    "                                           trainable = True)\n",
    "        self.attention_u = self.add_weight(name = \"atten_u\", shape = (self.attention_size,),\n",
    "                                           initializer = tf.random_uniform_initializer(), dtype = \"float32\",\n",
    "                                           trainable = True)\n",
    "        self.attention_b = self.add_weight(name = \"atten_b\", shape = (self.attention_size,),\n",
    "                                           initializer = tf.constant_initializer(0.1), dtype = \"float32\",\n",
    "                                           trainable = True)    \n",
    "        super().build(input_shape)\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        x = tf.tanh(tf.add(tf.tensordot(inputs, self.attention_w, axes = 1), self.attention_b))\n",
    "        x = tf.tensordot(x, self.attention_u, axes = 1)\n",
    "        x = tf.nn.softmax(x)\n",
    "        weight_out = tf.multiply(tf.expand_dims(x, -1), inputs)\n",
    "        final_out = tf.reduce_sum(weight_out, axis = 1) \n",
    "        drop_out = self.dropout(final_out, training = training)\n",
    "        return drop_out\n",
    "\n",
    "class RnnLayer(layers.Layer):\n",
    "    def __init__(self, rnn_size, drop_rate):\n",
    "        super().__init__()\n",
    "        fwd_lstm = LSTM(rnn_size, return_sequences = True, go_backwards= False, dropout = drop_rate,\n",
    "                        name = \"fwd_lstm\")\n",
    "        bwd_lstm = LSTM(rnn_size, return_sequences = True, go_backwards = True, dropout = drop_rate,\n",
    "                        name = \"bwd_lstm\")\n",
    "        self.bilstm = Bidirectional(merge_mode = \"concat\", layer = fwd_lstm, backward_layer = bwd_lstm,\n",
    "                                    name = \"bilstm\")\n",
    "    \n",
    "    def call(self, inputs, training):\n",
    "        outputs = self.bilstm(inputs, training = training)\n",
    "        return outputs\n",
    "\n",
    "class Model(tf.keras.Model):\n",
    "    def __init__(self, num_classes, drop_rate, vocab_size, embedding_size, rnn_size, attention_size):\n",
    "        super().__init__()\n",
    "        embedding_weight = self.get_embedding_weight(GLoVe_path, word_index)\n",
    "        self.embedding_layer = Embedding(vocab_size, embedding_size, weights=[embedding_weight],\n",
    "                                         name = \"embeding_0\")\n",
    "        self.rnn_layer = RnnLayer(rnn_size, drop_rate)\n",
    "        self.attention_layer = RnnAttentionLayer(attention_size, drop_rate)\n",
    "        self.dense_layer = Dense(num_classes, activation = \"softmax\", \n",
    "                                 kernel_regularizer=keras.regularizers.l2(0.001), name = \"dense_1\")\n",
    "\n",
    "    def call(self, input_x, training):\n",
    "        x = self.embedding_layer(input_x)\n",
    "        x = self.rnn_layer(x, training = training)\n",
    "        x = self.attention_layer(x, training = training)\n",
    "        x = self.dense_layer(x)\n",
    "        return x\n",
    "    \n",
    "    def get_embedding_weight(self, weight_path, word_index):\n",
    "        embedding_weight = np.random.uniform(-0.05, 0.05, size=[30000, 100])\n",
    "        cnt = 0\n",
    "        with open(weight_path, 'r') as f:\n",
    "            for line in f:\n",
    "                values = line.split()\n",
    "                word = values[0].lower()\n",
    "                if word in word_index.keys() and word_index[word]< 30000:\n",
    "                    weight = np.asarray(values[1:], dtype='float32')\n",
    "                    embedding_weight[word_index[word]] = weight\n",
    "                    cnt += 1\n",
    "        print('word num: {}, matched num: {}'.format(len(word_index), cnt))\n",
    "        return embedding_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6a738e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(xy_train, xy_val, num_classes, vocab_size, epoches, batch_size):\n",
    "    best_acc = 0\n",
    "    uniq_cfg_name = datetime.datetime.now().strftime(\"%Y\")\n",
    "    checkpoint_prefix = os.path.join(os.getcwd(), \"checkpoints2\")\n",
    "    if not os.path.exists(checkpoint_prefix):\n",
    "        print(\"create model dir: %s\" % checkpoint_prefix)\n",
    "        os.mkdir(checkpoint_prefix)\n",
    "\n",
    "    checkpoint_path = os.path.join(checkpoint_prefix, uniq_cfg_name)\n",
    "    model = Model(num_classes, drop_rate = 0.05, vocab_size = vocab_size, embedding_size = 100,\n",
    "                  rnn_size = 128, attention_size = 128)\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_weights(checkpoint_path)\n",
    "        print(\"load weight from: %s\" % checkpoint_path)\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(0.01)\n",
    "    loss_fn = tf.keras.losses.CategoricalCrossentropy()\n",
    "    \n",
    "    loss_metric = tf.keras.metrics.Mean(name='train_loss')\n",
    "    accuracy_metric = tf.keras.metrics.CategoricalAccuracy(name='train_accuracy')\n",
    "    \n",
    "    @tf.function \n",
    "    def train_step(input_x, input_y, training = True):\n",
    "        if training:\n",
    "            with tf.GradientTape() as tape:\n",
    "                raw_prob = model(input_x, training)\n",
    "                pred_loss = loss_fn(input_y, raw_prob)\n",
    "            gradients = tape.gradient(pred_loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "        else:\n",
    "            raw_prob = model(input_x, training)\n",
    "            pred_loss = loss_fn(input_y, raw_prob)\n",
    "        # Update the metrics\n",
    "        loss_metric.update_state(pred_loss)\n",
    "        accuracy_metric.update_state(input_y, raw_prob)\n",
    "        return raw_prob \n",
    "\n",
    "    for i in range(epoches):\n",
    "        t0 = time.time()\n",
    "        batch_train = batch_iter(xy_train[0], xy_train[1], batch_size = batch_size)\n",
    "        loss_metric.reset_states()\n",
    "        accuracy_metric.reset_states()\n",
    "\n",
    "        for batch_no, batch_tot, data_x, data_y in batch_train:\n",
    "            predict_prob = train_step(data_x, data_y, True)  \n",
    "      \n",
    "        print(\"[train ep %d] [%s]: %0.3f  [%s]: %0.3f\" %  (i, \"loss\", loss_metric.result() ,\n",
    "                                                           \"acc\", accuracy_metric.result()))\n",
    "\n",
    "        model.save_weights(checkpoint_path, overwrite=True)\n",
    "        \n",
    "        loss_metric.reset_states()\n",
    "        accuracy_metric.reset_states()\n",
    "        batch_test = batch_iter(xy_val[0], xy_val[1], batch_size = batch_size)\n",
    "        for _, _, data_x, data_y in batch_test:\n",
    "            train_step(data_x, data_y, False)\n",
    "        print(\"[***** ep %d] [%s]: %0.3f  [%s]: %0.3f\" %  (i, \"loss\", loss_metric.result() ,\n",
    "                                                           \"acc\", accuracy_metric.result()))\n",
    "        if accuracy_metric.result()>best_acc:\n",
    "            model.save('./model2/fake_news_cls')\n",
    "            best_acc=accuracy_metric.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4c446b22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "word num: 30000, matched num: 18702\n",
      "[train ep 0] [loss]: 0.171  [acc]: 0.927\n",
      "[***** ep 0] [loss]: 0.081  [acc]: 0.966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model2/fake_news_cls/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model2/fake_news_cls/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train ep 1] [loss]: 0.036  [acc]: 0.988\n",
      "[***** ep 1] [loss]: 0.087  [acc]: 0.970\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_fn, rnn_attention_dropout_layer_call_and_return_conditional_losses, rnn_attention_dropout_layer_call_and_return_conditional_losses while saving (showing 5 of 15). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model2/fake_news_cls/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./model2/fake_news_cls/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[train ep 2] [loss]: 0.010  [acc]: 0.997\n",
      "[***** ep 2] [loss]: 0.102  [acc]: 0.970\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    max_seq_len = 256\n",
    "    num_classes = 2\n",
    "    vocab_size = 30000\n",
    "    train_path='/Users/wangshihang/Documents/Code/fake-news/train2.csv'\n",
    "    test_path='/Users/wangshihang/Documents/Code/fake-news/valid.csv'\n",
    "    GLoVe_path = '/Users/wangshihang/Documents/Code/Glove/glove.twitter.27B.100d.txt'\n",
    "\n",
    "    ### gen samples ###\n",
    "    train_x, train_y = load_data(train_path, max_seq_len, word_index, num_classes)\n",
    "    test_x, test_y = load_data(test_path, max_seq_len, word_index, num_classes)\n",
    "    key, freq = np.unique(np.argmax(train_y, axis = 1), return_counts = True)\n",
    "    train([train_x, train_y], [test_x, test_y], num_classes, vocab_size, epoches = 3, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f3a2ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "max_seq_len = 256\n",
    "num_classes = 2\n",
    "test_path='/Users/wangshihang/Documents/Code/fake-news/valid.csv'\n",
    "test_x, test_y = load_data(test_path, max_seq_len, word_index, num_classes)\n",
    "\n",
    "model = tf.keras.models.load_model(\"./model2/fake_news_cls\")\n",
    "preds = []\n",
    "for i in range(94):\n",
    "    input_x=test_x[i*32:(i+1)*32]\n",
    "    raw_prob = model(input_x, training=False).numpy()\n",
    "    label = np.argmax(raw_prob,axis=1)\n",
    "    preds.extend(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5e1f617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "labels=np.argmax(test_y, axis=1)\n",
    "cm=confusion_matrix(preds, labels)\n",
    "cm_display = ConfusionMatrixDisplay(cm).plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59afe6b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.9703333333333334\n",
      "pre:  0.9703326534811794\n",
      "rcl:  0.9703357890544999\n",
      "f1:  0.970333250925697\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print('acc: ', metrics.accuracy_score(labels, preds))\n",
    "print('pre: ', metrics.precision_score(labels, preds, average='macro'))\n",
    "print('rcl: ', metrics.recall_score(labels, preds, average='macro'))\n",
    "print('f1: ', metrics.f1_score(labels, preds, average='macro'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dafe97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
